{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to try the creation of neural networks in Julia, we will use the well-known MINST dataset. \n",
    "    \n",
    "As a language that leans towards numerical computation, it’s no surprise that Julia offers a number of choices for doing deep learning, here are the stable libraries:\n",
    "\n",
    " - Flux.jl - The Elegant Machine Learning Stack.\n",
    " - Knet.jl - Koç University deep learning framework.\n",
    " - MLJ.jl - Julia machine learning framework by Alan Turing Institute.\n",
    " - MXNet.jl - Apache MXNet Julia package.\n",
    " - TensorFlow.jl - A Julia wrapper for TensorFlow. \n",
    " \n",
    " In this ocasion, we will use the Flux.jl package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUDA110\n",
      "\u001b[?25l\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUDNN_CUDA110\n",
      "\u001b[?25l\u001b[1A\u001b[2K\u001b[?25h\u001b[32m\u001b[1mDownloading\u001b[22m\u001b[39m artifact: CUTENSOR_CUDA110\n",
      "\u001b[?25l\u001b[1A\u001b[2K\u001b[?25h"
     ]
    }
   ],
   "source": [
    "using Flux, Flux.Data.MNIST\n",
    "using Flux:onehotbatch, argmax, crossentropy, throttle\n",
    "using Base.Iterators:repeated\n",
    "using Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST images and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = MNIST.images();\n",
    "imgs_test = MNIST.images(:test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = MNIST.labels();\n",
    "labels_test = MNIST.labels(:test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(imgs_train) = (60000,)\n",
      "size(labels_train) = (60000,)\n",
      "size(imgs_test) = (10000,)\n",
      "size(labels_test) = (10000,)\n"
     ]
    }
   ],
   "source": [
    "@show size(imgs_train)\n",
    "@show size(labels_train);\n",
    "@show size(imgs_test);\n",
    "@show size(labels_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAF3SURBVGje7dg9Sx1BGIbhK2IZAh4sJZBGCShEEEQbwRQGrK3SWAppTJW/kM5CQbCytlUsJH9BAmlShBAQBbEQ0UKLRFPM9mfPLnhmX+Zp9i129+bmYfZjKCkpKSkpKSnpfl60vcEaDrCBPTz1OX/kuQ3jA1t3eIp31fwGZ7kZFmAB5g8cbXPxNCaq+R7/cjSMD2zV4UeMV/MmLnI0jA9s1WGvOt7hMlfD+MDGHb7EfDUf4yhXw/jAxh0uYKaa667BoRjGBzbq8BXeVvM1tnM2jA9s1OEsPkv97eJPzobxgY3+8U/wXupwEb9yNowPHHgdjuGn1OFfPOZuGB84cIdzWMUVdvA7d8P4wIE67OGrtC96iP0uGMYH1u5wDJ+k/e1v+KLevszQDeMDa3/TrGBL6nJZeid2wjA+sPY6XMcUzvHQJcP4wFodfsAkfmAJt10yjA/s+yx9Lf3/3Uhdfu+aYXxg33U4Up20qX1/QzGMDywpKSkpaZ//C5EsSG1T/QUAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray, imgs[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the gray scale values into Float32 and vectorize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFloat32(x) = Float32.(x);\n",
    "vectorize(x) = x[:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(ftp_imgs_train) = (60000,)\n",
      "typeof(ftp_imgs_train) = Array{Array{Float32,2},1}\n"
     ]
    }
   ],
   "source": [
    "ftp_imgs_train = myFloat32.(imgs_train)\n",
    "ftp_imgs_test = myFloat32.(imgs_test);\n",
    "\n",
    "@show size(ftp_imgs_train)\n",
    "@show typeof(ftp_imgs_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(vec_imgs_train) = (60000,)\n",
      "typeof(vec_imgs_train) = Array{Array{Float32,1},1}\n"
     ]
    }
   ],
   "source": [
    "vec_imgs_train = vectorize.(ftp_imgs_train)\n",
    "vec_imgs_test = vectorize.(ftp_imgs_test);\n",
    "\n",
    "@show size(vec_imgs_train)\n",
    "@show typeof(vec_imgs_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all images in one matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(X_train) = (784, 60000)\n",
      "size(X_test) = (784, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train = hcat(vec_imgs_train...);\n",
    "X_test = hcat(vec_imgs_test...);\n",
    "@show size(X_train)\n",
    "@show size(X_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every column in X is an image of a number. There are 60,000 images for training and 10.000 for testing. We can reshape a column into a 28x28 matrix and display the corresponding images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAGlSURBVGje7dixS5VRHMbxj3IJWhILESGCBmmzqSEHCy5EtDcpbhr0bzQFzk0ODjVGOjU0OVmko5EJQVJDWyAkgVDDe8Dee68k773kuT/Osxzuue99vuc5D+d9uS9FRUVFRUVFRcOvkUEbtvECd7DX4/vR/50wPrDVOTGHK3jV0PAWtnNKGB/Y1eFdTGvW4Siu45rTD3j8LT3/Dhex1dBsCkt4jo+5JIwP7OqwnxWspnE/p4TxgbUOZzDZh9lYGt/klDA+sNbhA1xsaDSpehbCt5wSxgfWOryRxt0GRiuqHj/hMKeE8YGtXpPvz/jjS7iPBdxLc0/wI6eE8YE9O7zc8flmWlkbV3EB82nuCO/wK5nt5JYwPrD2N+4ZHqnO0cFf8zPpwmP8xAdVb9vYxHd8xbiq36wSxgfWzuFjfMFsx0UH2FB197aHyTIm8DnHhPGBXffSpw1M2ml8mWPC+MBW/xYnWs8xYQEWYP7AgZ3DEdW78n+9a42/pcPb4e8zrj7+lg5vh3Aba7kljA8c6L00y4TxgQPp8DUe5powPrCoqKioqH/9ATeSLmyCLr3XAAAAAElFTkSuQmCC",
      "text/plain": [
       "28×28 reinterpret(Gray{Float32}, ::Array{Float32,2}):\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱  \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = X_train[:,3]\n",
    "t1 = reshape(figure, 28, 28)\n",
    "colorview(Gray, t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the labels en formato *OneHot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×60000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  1  0  0  1  0  1  0  0  0  0     0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  0  0  0  0  1  0  0  0  0  0  0  0     0  0  0  1  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  1  0  0  1  0  1     0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  1  0  0  0  0  0  0  1  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  1  0  …  0  0  0  0  0  1  0  0  0  1  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     1  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  1  0  0  0  0  0  1  0  0  0  1\n",
       " 0  0  0  0  1  0  0  0  0  0  0  0  0     0  0  1  0  1  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = Flux.onehotbatch(labels_train, 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(X_train) = (784, 60000)\n",
      "size(Y_train) = (10, 60000)\n",
      "size(X_test) = (784, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(784, 10000)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show size(X_train)\n",
    "@show size(Y_train)\n",
    "@show size(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "\n",
    "The neural network will have one single hidden layer with 32 neurons  and *relu* activation and a output layer (with obviously 10 nodes)with *softwax* activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions\n",
    "INPUT_SIZE = size(X_train,1)\n",
    "HIDDEN_SIZE = 32\n",
    "OUTPUT_SIZE = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Flux.Dense(INPUT_SIZE, HIDDEN_SIZE, Flux.relu)\n",
    "hidden_layer = Flux.Dense(HIDDEN_SIZE, OUTPUT_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 32, relu), Dense(32, 10), softmax)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Flux.Chain(input_layer, hidden_layer, Flux.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = Flux.crossentropy(network(x), y)\n",
    "ps = Flux.params(network)\n",
    "data = Iterators.repeated((X_train,Y_train), 200)\n",
    "opt = Flux.ADAM()\n",
    "evalcb = () -> @show(loss(X_train,Y_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X_train, Y_train) = 0.2856005f0\n",
      "loss(X_train, Y_train) = 0.22999921f0\n",
      "loss(X_train, Y_train) = 0.19141106f0\n",
      "loss(X_train, Y_train) = 0.16281606f0\n",
      "loss(X_train, Y_train) = 0.14071596f0\n",
      "loss(X_train, Y_train) = 0.12313181f0\n",
      "loss(X_train, Y_train) = 0.108887665f0\n"
     ]
    }
   ],
   "source": [
    "Flux.train!(loss, ps, data, opt, cb = throttle(evalcb,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Array{Int64,1}:\n",
       " 7\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 4\n",
       " 1\n",
       " 4\n",
       " 9\n",
       " 6\n",
       " 9\n",
       " 0\n",
       " 6\n",
       " 9\n",
       " ⋮\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mapslices(argmax,network(X_test),dims=1)[:] .-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum(predictions .== labels_test) / size(labels_test,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
